{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Multiple Label Studio Annotator Exports — ARI3129 Assignment 2025/26\n",
    "\n",
    "\n",
    "This notebook combines 2–4 Label Studio JSON files (each from a different annotator) and 2–4 ZIPs of images into a single unified dataset.\n",
    "\n",
    "Output:\n",
    "- `Individuals` - folder containing all uploaded per-annotator original JSON and ZIP files (saved as `input_{name}.json` and `images_{name}.zip`)\n",
    "- `Merger/merged_input.json` — merged Label Studio task array (all annotations combined)\n",
    "- `Merger/merged_images.zip` — flattened, deduplicated set of all unique images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e9fc3",
   "metadata": {},
   "source": [
    "## 1) Environment and Dependency Setup\n",
    "\n",
    "This section ensures that all required Python packages are available before the notebook is run.  \n",
    "If any dependency such as `ipywidgets` or `IPython` is missing, it is automatically installed using `pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# --- Standard library ---\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Set\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timezone\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# --- Package bootstrap helper ---\n",
    "def ensure_package(pkg: str, import_name: str | None = None):\n",
    "    try:\n",
    "        return importlib.import_module(import_name or pkg)\n",
    "    except ImportError:\n",
    "        print(f\"Installing missing package: {pkg}\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "        return importlib.import_module(import_name or pkg)\n",
    "\n",
    "# --- Ensure and import third-party packages ---\n",
    "ensure_package(\"ipywidgets\")\n",
    "ensure_package(\"IPython.display\", \"IPython.display\")\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "print(\"Environment ready: required dependencies installed and imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ea8e7",
   "metadata": {},
   "source": [
    "## 2) Consolidate Members’ Exports\n",
    "\n",
    "This section merges multiple team members’ **Label Studio JSON** files and their **images ZIPs** into a single, consolidated set for downstream conversion.\n",
    "\n",
    "**How to use**\n",
    "1. Set **Team size** (2–4) and click **Set team size**.  \n",
    "2. For each member, enter **Full name**, upload **Annotation JSON** and **Images ZIP**.  \n",
    "3. Click **Merge**.  \n",
    "4. Check the output panel for paths, counts, and any validation errors.\n",
    "\n",
    "<div style=\"border:3px solid #c00; background:#fff7f7; padding:12px; border-radius:6px\">\n",
    "    <strong style=\"color:#000000\">⚠️ IMPORTANT</strong>\n",
    "    <ul>\n",
    "        <li style=\"color:#000000\">If a white box appears with no buttons or widgets, restart the kernel and re-run the notebook cells one by one.</li>\n",
    "        <li style=\"color:#000000\">Ensure that you upload each team member's <strong>JSON</strong> and <strong>ZIP</strong> pair corresponding to their own Label Studio annotations and images.</li>\n",
    "    </ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Paths ----\n",
    "ROOT_DIR    = Path.cwd()\n",
    "MERGER_DIR  = ROOT_DIR / \"Merger\"\n",
    "INDIV_DIR   = MERGER_DIR / \"Individuals\"\n",
    "IMG_WORK    = MERGER_DIR / \"Temp\"  # temporary extraction workspace\n",
    "for d in (MERGER_DIR, INDIV_DIR, IMG_WORK):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMAGE_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
    "\n",
    "# ---- Widgets (step 1: team size) ----\n",
    "team_size_input = widgets.BoundedIntText(value=2, min=2, max=4, step=1, description=\"Team size\")\n",
    "build_team_btn  = widgets.Button(description=\"Set team size\", button_style=\"info\")\n",
    "team_box        = widgets.VBox([widgets.HTML(\"<b>Step 1)</b> Enter number of team members (2–4).\"), team_size_input, build_team_btn])\n",
    "\n",
    "# Placeholder containers (populated after size set)\n",
    "members_ui_box = widgets.VBox([])\n",
    "run_btn        = widgets.Button(description=\"Merge to merged_input.json + merged_images.zip\", button_style=\"success\", icon=\"check\")\n",
    "out_box        = widgets.Output(layout=widgets.Layout(border=\"1px solid #ddd\", padding=\"8px\"))\n",
    "\n",
    "display(widgets.VBox([\n",
    "    team_box,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    widgets.HTML(\"<b>Step 2)</b> Provide full name and uploads for each member.\"),\n",
    "    members_ui_box,\n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    run_btn,\n",
    "    out_box\n",
    "]))\n",
    "\n",
    "# ---- Helpers ----\n",
    "def _safe_name(s: str) -> str:\n",
    "    return \"\".join(ch if ch.isalnum() or ch in (\" \", \"_\", \"-\", \".\") else \"_\" for ch in (s or \"\").strip())\n",
    "\n",
    "def _save_fileupload_single(u: widgets.FileUpload, dest_path: Path) -> Path:\n",
    "    v = u.value\n",
    "    if not v:\n",
    "        raise RuntimeError(\"No file uploaded.\")\n",
    "\n",
    "    # ipywidgets 7: dict of {filename: {content: ...}}\n",
    "    if isinstance(v, dict):\n",
    "        first = next(iter(v.values()))\n",
    "    # ipywidgets 8: tuple/list of {name, type, size, last_modified, content}\n",
    "    elif isinstance(v, (tuple, list)):\n",
    "        first = v[0]\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unexpected FileUpload.value type: {type(v)}\")\n",
    "\n",
    "    with dest_path.open(\"wb\") as f:\n",
    "        f.write(first[\"content\"])\n",
    "    return dest_path\n",
    "\n",
    "def _load_ls_array(p: Path) -> List[Dict[str, Any]]:\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"{p.name} is not a Label Studio task array.\")\n",
    "    return data\n",
    "\n",
    "def _task_key(task: Dict[str, Any]) -> str:\n",
    "    fu = task.get(\"file_upload\")\n",
    "    if fu:\n",
    "        return str(fu)\n",
    "    img = (task.get(\"data\") or {}).get(\"image\", \"\")\n",
    "    return Path(img).name or str(img)\n",
    "\n",
    "def _merge_ls_tasks(task_lists: List[List[Dict[str, Any]]]) -> List[Dict[str, Any]]:\n",
    "    bucket: Dict[str, List[Dict[str, Any]]] = defaultdict(list)\n",
    "    for tl in task_lists:\n",
    "        for t in tl:\n",
    "            bucket[_task_key(t)].append(t)\n",
    "\n",
    "    merged: List[Dict[str, Any]] = []\n",
    "    for key, tasks in bucket.items():\n",
    "        tasks_sorted = sorted(tasks, key=lambda t: len(t.get(\"annotations\", [])), reverse=True)\n",
    "        base = json.loads(json.dumps(tasks_sorted[0]))  # deep copy\n",
    "        all_anns: List[Dict[str, Any]] = []\n",
    "        for t in tasks:\n",
    "            anns = t.get(\"annotations\", []) or []\n",
    "            all_anns.extend(anns)\n",
    "\n",
    "        new_anns: List[Dict[str, Any]] = []\n",
    "        next_id = 1\n",
    "        for ann in all_anns:\n",
    "            ann_copy = json.loads(json.dumps(ann))\n",
    "            ann_copy[\"id\"] = next_id\n",
    "            next_id += 1\n",
    "            for r in ann_copy.get(\"result\", []) or []:\n",
    "                r[\"id\"] = r.get(\"id\") or f\"res_{ann_copy['id']}_{hashlib.md5(str(r).encode()).hexdigest()[:6]}\"\n",
    "            new_anns.append(ann_copy)\n",
    "\n",
    "        base[\"annotations\"] = new_anns\n",
    "        merged.append(base)\n",
    "    return merged\n",
    "\n",
    "def _sha1_of_file(p: Path, buf_size: int = 1 << 20) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with p.open(\"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(buf_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _extract_and_flatten_zips(zip_paths: List[Path], dest_dir: Path) -> Tuple[int, int]:\n",
    "    \"\"\"Extract all zips into dest_dir, dedupe by content hash, handle name clashes with short hash suffix.\"\"\"\n",
    "    if dest_dir.exists():\n",
    "        shutil.rmtree(dest_dir)\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    seen_hash: Dict[str, str] = {}\n",
    "    written = 0\n",
    "    skipped = 0\n",
    "\n",
    "    tmp_root = dest_dir.parent / \"_unzips_tmp\"\n",
    "    if tmp_root.exists():\n",
    "        shutil.rmtree(tmp_root)\n",
    "    tmp_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        for zp in zip_paths:\n",
    "            with zipfile.ZipFile(zp, \"r\") as zf:\n",
    "                zf.extractall(tmp_root)\n",
    "\n",
    "        for p in tmp_root.rglob(\"*\"):\n",
    "            if not p.is_file():\n",
    "                continue\n",
    "            if p.name.startswith(\"._\") or \"DS_Store\" in p.name:\n",
    "                continue\n",
    "            if p.suffix.lower() not in IMAGE_EXTENSIONS:\n",
    "                continue\n",
    "\n",
    "            sha1 = _sha1_of_file(p)\n",
    "            if sha1 in seen_hash:\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            base, ext = Path(p.name).stem, Path(p.name).suffix\n",
    "            dst = dest_dir / p.name\n",
    "            if dst.exists():  # different content, same name\n",
    "                dst = dest_dir / f\"{base}_{sha1[:8]}{ext}\"\n",
    "            shutil.copy2(p, dst)\n",
    "            seen_hash[sha1] = dst.name\n",
    "            written += 1\n",
    "    finally:\n",
    "        shutil.rmtree(tmp_root, ignore_errors=True)\n",
    "\n",
    "    return written, skipped\n",
    "\n",
    "def _zip_dir(src_dir: Path, out_zip: Path):\n",
    "    if out_zip.exists():\n",
    "        out_zip.unlink()\n",
    "    with zipfile.ZipFile(out_zip, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for p in sorted(src_dir.rglob(\"*\")):\n",
    "            if p.is_file():\n",
    "                zf.write(p, p.relative_to(src_dir))\n",
    "\n",
    "# ---- Build dynamic per-member UI ----\n",
    "member_rows: List[Dict[str, Any]] = []\n",
    "\n",
    "def _build_member_rows(_):\n",
    "    members_ui_box.children = []\n",
    "    member_rows.clear()\n",
    "    n = int(team_size_input.value)\n",
    "    if n < 2 or n > 4:\n",
    "        with out_box:\n",
    "            print(\"Team size must be between 2 and 4.\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    for i in range(1, n+1):\n",
    "        name_w = widgets.Text(description=f\"Member {i}:\", placeholder=\"Full name\")\n",
    "        json_u = widgets.FileUpload(accept=\".json\", multiple=False, description=\"Upload JSON\")\n",
    "        zip_u  = widgets.FileUpload(accept=\".zip\",  multiple=False, description=\"Upload ZIP\")\n",
    "        row = widgets.VBox([\n",
    "            widgets.HTML(f\"<b>Member {i}</b>\"),\n",
    "            name_w,\n",
    "            widgets.HBox([widgets.HTML(\"Annotation JSON:\"), json_u]),\n",
    "            widgets.HBox([widgets.HTML(\"Images ZIP:\"), zip_u]),\n",
    "            widgets.HTML(\"<hr>\")\n",
    "        ])\n",
    "        rows.append(row)\n",
    "        member_rows.append({\"name_widget\": name_w, \"json_upl\": json_u, \"zip_upl\": zip_u})\n",
    "    members_ui_box.children = rows\n",
    "\n",
    "build_team_btn.on_click(_build_member_rows)\n",
    "\n",
    "# ---- Main action ----\n",
    "def _run_merge(_):\n",
    "    with out_box:\n",
    "        clear_output()\n",
    "        try:\n",
    "            if not member_rows:\n",
    "                raise RuntimeError(\"Set team size and fill member sections first.\")\n",
    "\n",
    "            saved_jsons, saved_zips = [], []\n",
    "\n",
    "            for entry in member_rows:\n",
    "                full_name = entry[\"name_widget\"].value.strip()\n",
    "                if not full_name:\n",
    "                    raise RuntimeError(\"Each member must have a full name.\")\n",
    "                safe_full = _safe_name(full_name).replace(\" \", \"_\")\n",
    "\n",
    "                json_upl, zip_upl = entry[\"json_upl\"], entry[\"zip_upl\"]\n",
    "                if not json_upl.value:\n",
    "                    raise RuntimeError(f\"No JSON uploaded for {full_name}.\")\n",
    "                if not zip_upl.value:\n",
    "                    raise RuntimeError(f\"No ZIP uploaded for {full_name}.\")\n",
    "\n",
    "                json_path = INDIV_DIR / f\"input_{safe_full}.json\"\n",
    "                zip_path  = INDIV_DIR / f\"images_{safe_full}.zip\"\n",
    "                _save_fileupload_single(json_upl, json_path)\n",
    "                _save_fileupload_single(zip_upl,  zip_path)\n",
    "                saved_jsons.append(json_path)\n",
    "                saved_zips.append(zip_path)\n",
    "\n",
    "            task_lists = [_load_ls_array(p) for p in saved_jsons]\n",
    "            merged_tasks = _merge_ls_tasks(task_lists)\n",
    "            merged_input_path = MERGER_DIR / \"merged_input.json\"\n",
    "            with merged_input_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(merged_tasks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            written, skipped = _extract_and_flatten_zips(saved_zips, IMG_WORK)\n",
    "            merged_zip_path = MERGER_DIR / \"merged_images.zip\"\n",
    "            _zip_dir(IMG_WORK, merged_zip_path)\n",
    "\n",
    "            # delete temporary folder after merge\n",
    "            shutil.rmtree(IMG_WORK, ignore_errors=True)\n",
    "\n",
    "            display(Markdown(\"**Merge complete.**\"))\n",
    "            print(f\"Saved individuals in: {INDIV_DIR}\")\n",
    "            print(f\"Merged JSON: {merged_input_path}\")\n",
    "            print(f\"Merged images ZIP: {merged_zip_path}\")\n",
    "            print(f\"Images written: {written} | Duplicates skipped: {skipped}\")\n",
    "            print(f\"Merged tasks: {len(merged_tasks)}\")\n",
    "\n",
    "        except Exception as exc:\n",
    "            display(Markdown(f\"**Error:** {exc}\"))\n",
    "\n",
    "run_btn.on_click(_run_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step\n",
    "\n",
    "Once `merged_input.json` and `merged_images.zip` are generated in the `Merge/` directory, proceed to the conversion and validation notebook `(LS2COCO.ipynb)` that converts the merged Label Studio (JSON) export into COCO format, auto-matches image files, enriches attributes, and prepares the dataset for training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARI3129",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
